import json
from typing import Annotated, Any, TypedDict, List
import copy

from common_logic.common_utils.chatbot_utils import ChatbotManager
from common_logic.common_utils.constant import (
    ChatbotMode,
    IndexType,
    LLMTaskType,
    SceneType,
    ToolRuningMode,
)
from common_logic.common_utils.lambda_invoke_utils import (
    invoke_lambda,
    is_running_local,
    node_monitor_wrapper,
    send_trace,
)
from langchain_core.messages import ToolMessage,AIMessage
from common_logic.common_utils.logger_utils import get_logger
from common_logic.common_utils.prompt_utils import get_prompt_templates_from_ddb
from common_logic.common_utils.python_utils import add_messages, update_nest_dict
from common_logic.common_utils.response_utils import process_response
from common_logic.common_utils.serialization_utils import JSONEncoder
from langchain_integration.tools import ToolManager
from langchain_core.tools import BaseTool
from langchain_core.messages.tool import ToolCall
from langgraph.prebuilt import ToolNode
from langchain_integration.chains import LLMChain


# from lambda_main.main_utils.online_entries.agent_base import (
#     build_agent_graph,
#     tool_execution,
# )
from lambda_main.main_utils.parse_config import CommonConfigParser
from langgraph.graph import END, StateGraph
from langchain_integration.langgraph_integration import set_currrent_app

logger = get_logger("common_entry")


class ChatbotState(TypedDict):
    ########### input/output states ###########
    # inputs
    # origin event body
    event_body: dict
    # origianl input question
    query: str
    # chat history between human and agent
    chat_history: Annotated[list[dict], add_messages]
    # complete chatbot config, consumed by all the nodes
    chatbot_config: dict
    # websocket connection id for the agent
    ws_connection_id: str
    # whether to enbale stream output via ws_connection_id
    stream: bool
    # message id related to original input question
    message_id: str = None
    # record running states of different nodes
    trace_infos: Annotated[list[str], add_messages]
    # whether to enbale trace info update via streaming ouput
    enable_trace: bool
    # outputs
    # final answer generated by whole app graph
    answer: Any
    # information needed return to user, e.g. intention, context, figure and so on, anything you can get during execution
    extra_response: Annotated[dict, update_nest_dict]
    # addition kwargs which need to save into ddb
    ddb_additional_kwargs: dict
    # response of entire app
    app_response: Any

    ########### query rewrite states ###########
    # query rewrite results
    query_rewrite: str = None

    ########### intention detection states ###########
    # intention type of retrieved intention samples in search engine, e.g. OpenSearch
    intent_type: str = None
    # retrieved intention samples in search engine, e.g. OpenSearch
    intent_fewshot_examples: list
    # tools of retrieved intention samples in search engine, e.g. OpenSearch
    intent_fewshot_tools: list

    ########### retriever states ###########
    # contexts information retrieved in search engine, e.g. OpenSearch
    qq_match_results: list = []
    contexts: str = None
    figure: list = None

    ########### agent states ###########
    # current output of agent
    # agent_current_output: dict
    # # record messages during agent tool choose and calling, including agent message, tool ouput and error messages
    agent_tool_history: Annotated[List[AIMessage | ToolMessage], add_messages]
    # # the maximum number that agent node can be called
    # agent_repeated_call_limit: int
    # # the current call time of agent
    # agent_current_call_number: int  #
    # # whehter the current call time is less than maximum number of agent call
    # agent_repeated_call_validation: bool
    # # function calling
    # # whether the output of agent can be parsed as the valid tool calling
    # function_calling_parse_ok: bool
    # # whether the current parsed tool calling is run once
    tool_calling_is_run_once: bool
    # # current tool calls
    # function_calling_parsed_tool_calls: list
    # current_agent_tools_def: list
    last_tool_messages: List[ToolMessage]
    tools: List[BaseTool]
    # the global rag tool use all knowledge
    all_knowledge_rag_tool: BaseTool


def is_null_or_empty(value):
    if value is None:
        return True
    elif isinstance(value, (dict, list, str)) and not value:
        return True
    return False


def format_intention_output(data):
    if is_null_or_empty(data):
        return ""

    markdown_table = "| Query                | Score | Name       | Intent      | Additional Info      |\n"
    markdown_table += "|----------------------|-------|------------|-------------|----------------------|\n"
    for item in data:
        query = item.get("query", "")
        score = item.get("score", "")
        name = item.get("name", "")
        intent = item.get("intent", "")
        kwargs = ', '.join([f'{k}: {v}' for k, v in item.get('kwargs', {}).items()])
        markdown_table += f"| {query} | {score} | {name} | {intent} | {kwargs} |\n"
        logger.info(markdown_table)

    return markdown_table

####################
# nodes in graph #
####################


@node_monitor_wrapper
def query_preprocess(state: ChatbotState):
    output: str = invoke_lambda(
        event_body=state,
        lambda_name="Online_Query_Preprocess",
        lambda_module_path="lambda_query_preprocess.query_preprocess",
        handler_name="lambda_handler",
    )

    send_trace(f"\n**query rewrite:** {output}\n**origin query:** {state['query']}")
    return {"query_rewrite": output}


@node_monitor_wrapper
def intention_detection(state: ChatbotState):
    # if state['chatbot_config']['agent_config']['only_use_rag_tool']:
    #     return {
    #         "intent_type": "intention detected"
    #     }
    retriever_params = state["chatbot_config"]["qq_match_config"]
    retriever_params["query"] = state[
        retriever_params.get("retriever_config", {}).get("query_key", "query")
    ]
    output: str = invoke_lambda(
        event_body=retriever_params,
        lambda_name="Online_Functions",
        lambda_module_path="functions.functions_utils.retriever.retriever",
        handler_name="lambda_handler",
    )
    context_list = []
    qq_match_threshold = retriever_params["threshold"]
    for doc in output["result"]["docs"]:
        if doc["retrieval_score"] > qq_match_threshold:
            send_trace(
                f"\n\n**similar query found**\n{doc}",
                state["stream"],
                state["ws_connection_id"],
                state["enable_trace"],
            )
            query_content = doc["answer"]
            # query_content = doc['answer']['jsonlAnswer']
            return {
                "answer": query_content,
                "intent_type": "similar query found",
            }
        question = doc["question"]
        answer = doc["answer"]
        context_list.append(f"问题: {question}, \n答案：{answer}")

    if state["chatbot_config"]["agent_config"]["only_use_rag_tool"]:
        return {"qq_match_results": context_list, "intent_type": "intention detected"}

    intent_fewshot_examples = invoke_lambda(
        lambda_module_path="lambda_intention_detection.intention",
        lambda_name="Online_Intention_Detection",
        handler_name="lambda_handler",
        event_body=state,
    )

    intent_fewshot_tools: list[str] = list(
        set([e["intent"] for e in intent_fewshot_examples])
    )

    markdown_table = format_intention_output(intent_fewshot_examples)
    send_trace(
        f"**intention retrieved:**\n\n {markdown_table}",
        state["stream"],
        state["ws_connection_id"],
        state["enable_trace"],
    )
    return {
        "intent_fewshot_examples": intent_fewshot_examples,
        "intent_fewshot_tools": intent_fewshot_tools,
        "qq_match_results": context_list,
        "intent_type": "intention detected",
    }


@node_monitor_wrapper
def agent(state: ChatbotState):
    # two cases to invoke rag function
    # 1. when valid intention fewshot found
    # 2. for the first time, agent decides to give final results

    # deal with once tool calling
    last_tool_messages = state["last_tool_messages"]
    if last_tool_messages and len(last_tool_messages) == 1:
        last_tool_message = last_tool_messages[0]
        tool:BaseTool = ToolManager.get_tool(
            scene=SceneType.COMMON,
            name=last_tool_message.name
        )
        if tool.return_direct:
            send_trace("once tool", enable_trace=state["enable_trace"])
            return {"answer": last_tool_message.content, "tool_calling_is_run_once": True}

        # tool_execute_res = last_tool_calls_results[-1].additional_kwargs[
        #     "raw_tool_call_results"
        # ][0]
        # tool_name = tool_execute_res["name"]
        # output = tool_execute_res["output"]
        # tool = get_tool_by_name(tool_name, scene=SceneType.COMMON)
        # if tool.running_mode == ToolRuningMode.ONCE:
        #     send_trace("once tool", enable_trace=state["enable_trace"])
        #     return {"answer": output["result"], "tool_calling_is_run_once": True}
    


    # if state["agent_tool_history"] and state["agent_tool_history"][-1].type=="tool_call":
    #     tool_execute_res = state["agent_tool_history"][-1]["additional_kwargs"][
    #         "raw_tool_call_results"
    #     ][0]
    #     tool_name = tool_execute_res["name"]
    #     output = tool_execute_res["output"]
    #     tool = get_tool_by_name(tool_name, scene=SceneType.COMMON)
    #     if tool.running_mode == ToolRuningMode.ONCE:
    #         send_trace("once tool", enable_trace=state["enable_trace"])
    #         return {"answer": output["result"], "tool_calling_is_run_once": True}

    no_intention_condition = not state["intent_fewshot_examples"]
    # first_tool_final_response = False
    # if (
    #     (state["agent_current_call_number"] == 1)
    #     and state["function_calling_parse_ok"]
    #     and state["agent_tool_history"]
    # ):
    #     tool_execute_res = state["agent_tool_history"][-1]["additional_kwargs"][
    #         "raw_tool_call_results"
    #     ][0]
    #     tool_name = tool_execute_res["name"]
    #     if tool_name == "give_final_response":
    #         first_tool_final_response = True

    if (
        no_intention_condition
        # or first_tool_final_response
        or state["chatbot_config"]["agent_config"]["only_use_rag_tool"]
    ):
        if state["chatbot_config"]["agent_config"]["only_use_rag_tool"]:
            send_trace("agent only use rag tool", enable_trace=state["enable_trace"])
        elif no_intention_condition:
            send_trace(
                "no_intention_condition, switch to rag tool",
                enable_trace=state["enable_trace"],
            )
        # elif first_tool_final_response:
        #     send_trace(
        #         "first tool is final response, switch to rag tool",
        #         enable_trace=state["enable_trace"],
        #     )
         
        all_knowledge_rag_tool = state['all_knowledge_rag_tool']
        return AIMessage(content="",tool_calls=[
            ToolCall(
                name=all_knowledge_rag_tool.name,
                args={}
            )
        ])
    
    # response = app_agent.invoke(state)

    # normal call
    agent_config = state["chatbot_config"]['agent_config']
    tools_name = state['intent_fewshot_tools'] + agent_config['tools']
    # get tools from tool names
    tools = [
        ToolManager.get_tool(
            scene=SceneType.COMMON,
            name=name
            ) 
        for name in tools_name
    ]
    llm_config = {
        **agent_config['llm_config'],
        "tools": tools,
        "fewshot_examples": state['intent_fewshot_examples'],
    }
    group_name = state['chatbot_config']['group_name']
    chatbot_id = state['chatbot_config']['chatbot_id']
    prompt_templates_from_ddb = get_prompt_templates_from_ddb(
        group_name,
        model_id = llm_config['model_id'],
        task_type=LLMTaskType.TOOL_CALLING_API,
        chatbot_id=chatbot_id
    )
    llm_config.update(**prompt_templates_from_ddb)

    tool_calling_chain = LLMChain.get_chain(
        intent_type=LLMTaskType.TOOL_CALLING_API,
        scene=SceneType.COMMON,
        **llm_config
    )
    agent_message:AIMessage = tool_calling_chain.invoke(**state)
    send_trace(
        # f"\n\n**agent_current_output:** \n{agent_message}\n\n **agent_current_call_number:** {agent_current_call_number}",
        f"\n\n**agent_current_output:** \n{agent_message}\n\n",
        state["stream"],
        state["ws_connection_id"]
    )

    return {"agent_tool_history":[agent_message],"tools":tools}


@node_monitor_wrapper
def llm_direct_results_generation(state: ChatbotState):
    group_name = state["chatbot_config"]["group_name"]
    llm_config = state["chatbot_config"]["chat_config"]
    task_type = LLMTaskType.CHAT

    prompt_templates_from_ddb = get_prompt_templates_from_ddb(
        group_name, model_id=llm_config["model_id"], task_type=task_type
    )
    logger.info(prompt_templates_from_ddb)

    answer: dict = invoke_lambda(
        event_body={
            "llm_config": {
                **llm_config,
                "stream": state["stream"],
                "intent_type": task_type,
                **prompt_templates_from_ddb,
            },
            "llm_input": {
                "query": state["query"],
                "chat_history": state["chat_history"],
            },
        },
        lambda_name="Online_LLM_Generate",
        lambda_module_path="lambda_llm_generate.llm_generate",
        handler_name="lambda_handler",
    )
    return {"answer": answer}


@node_monitor_wrapper
def tool_execution(state):
    """executor lambda
    Args:
        state (NestUpdateState): _description_

    Returns:
        _type_: _description_
    """
    tools:List[BaseTool] = state['tools']
    tool_node = ToolNode(tools)
    last_agent_message:AIMessage = state["agent_tool_history"][-1]
    
    # pass state to tools if needed
    tools_map = {tool.name:tool for tool in tools}
    tool_calls:List[ToolCall] = copy.deepcopy(last_agent_message.tool_calls)

    for tool_call in tool_calls:
        tool = tools_map[tool_call.name]
        if tool.pass_state:
            tool_call.args.update({tool.pass_state_name:state})

    tool_messages:List[ToolMessage] = tool_node.invoke(
        [AIMessage(content="",tool_calls=tool_calls)]
    )

    # tool_calls = state['function_calling_parsed_tool_calls']
    # assert len(tool_calls) == 1, tool_calls
    # tool_call_results = []
    # for tool_call in tool_calls:
    #     tool_name = tool_call["name"]
    #     tool_kwargs = tool_call['kwargs']
    #     # call tool
    #     output = invoke_lambda(
    #         event_body = {
    #             "tool_name":tool_name,
    #             "state":state,
    #             "kwargs":tool_kwargs
    #             },
    #         lambda_name="Online_Tool_Execute",
    #         lambda_module_path="functions.lambda_tool",
    #         handler_name="lambda_handler"   
    #     )
    #     tool_call_results.append({
    #         "name": tool_name,
    #         "output": output,
    #         "kwargs": tool_call['kwargs'],
    #         "model_id": tool_call['model_id']
    #     })
    
    # output = format_tool_call_results(tool_call['model_id'],tool_call_results)
    send_trace(f'**tool_execute_res:** \n{tool_messages}', enable_trace=state["enable_trace"])
    return {
            "agent_tool_history": tool_messages,
            "last_tool_messages": tool_messages
        }


def final_results_preparation(state: ChatbotState):
    app_response = process_response(state["event_body"], state)
    return {"app_response": app_response}


def matched_query_return(state: ChatbotState):
    return {"answer": state["answer"]}


################
# define edges #
################


def query_route(state: dict):
    return f"{state['chatbot_config']['chatbot_mode']} mode"


def intent_route(state: dict):
    return state["intent_type"]


def agent_route(state: dict):
    if state.get("tool_calling_is_run_once", False):
        return "no need tool calling"

    # state["agent_repeated_call_validation"] = (
    #     state["agent_current_call_number"] < state["agent_repeated_call_limit"]
    # )

    if state["agent_repeated_call_validation"]:
        return "valid tool calling"
    else:
        # TODO give final strategy
        raise RuntimeError


#############################
# define online top-level graph for app #
#############################


def build_graph(chatbot_state_cls):
    workflow = StateGraph(chatbot_state_cls)

    # add node for all chat/rag/agent mode
    workflow.add_node("query_preprocess", query_preprocess)
    # chat mode
    workflow.add_node("llm_direct_results_generation", llm_direct_results_generation)
    # rag mode
    # workflow.add_node("knowledge_retrieve", knowledge_retrieve)
    # workflow.add_node("llm_rag_results_generation", llm_rag_results_generation)
    # agent mode
    workflow.add_node("intention_detection", intention_detection)
    workflow.add_node("matched_query_return", matched_query_return)
    # agent sub graph
    workflow.add_node("agent", agent)
    workflow.add_node("tools_execution", tool_execution)
    workflow.add_node("final_results_preparation", final_results_preparation)

    # add all edges
    workflow.set_entry_point("query_preprocess")
    # chat mode
    workflow.add_edge("llm_direct_results_generation", "final_results_preparation")
    # rag mode
    # workflow.add_edge("knowledge_retrieve", "llm_rag_results_generation")
    # workflow.add_edge("llm_rag_results_generation", END)
    # agent mode
    workflow.add_edge("tools_execution", "agent")
    workflow.add_edge("matched_query_return", "final_results_preparation")
    workflow.add_edge("final_results_preparation", END)

    # add conditional edges
    # choose running mode based on user selection:
    # 1. chat mode: let llm generate results directly
    # 2. rag mode: retrive all knowledge and let llm generate results
    # 3. agent mode: let llm generate results based on intention detection, tool calling and retrieved knowledge
    workflow.add_conditional_edges(
        "query_preprocess",
        query_route,
        {
            "chat mode": "llm_direct_results_generation",
            "agent mode": "intention_detection",
        },
    )

    # three running branch will be chosen based on intention detection results:
    # 1. similar query found: if very similar queries were found in knowledge base, these queries will be given as results
    # 2. intention detected: if intention detected, the agent logic will be invoked
    workflow.add_conditional_edges(
        "intention_detection",
        intent_route,
        {
            "similar query found": "matched_query_return",
            "intention detected": "agent",
        },
    )

    # the results of agent planning will be evaluated and decide next step:
    # 1. valid tool calling: the agent chooses the valid tools, and the tools will be executed
    # 2. no need tool calling: the agent thinks no tool needs to be called, the final results can be generated
    workflow.add_conditional_edges(
        "agent",
        agent_route,
        {
            "valid tool calling": "tools_execution",
            "no need tool calling": "final_results_preparation",
        },
    )

    app = workflow.compile()
    return app


#####################################
# define online sub-graph for agent #
#####################################
# app_agent = None
app = None


# def register_rag_tool(
#     name: str,
#     description: str,
#     scene=SceneType.COMMON,
#     lambda_name: str = "lambda_common_tools",
# ):
#     tool_manager.register_tool(
#         {
#             "name": name,
#             "scene": scene,
#             "lambda_name": lambda_name,
#             "lambda_module_path": rag.lambda_handler,
#             "tool_def": {
#                 "name": name,
#                 "description": description,
#             },
#             "running_mode": ToolRuningMode.ONCE,
#         }
#     )

def register_rag_tool_from_config(event_body: dict):
    group_name = event_body.get("chatbot_config").get("group_name", "Admin")
    chatbot_id = event_body.get("chatbot_config").get("chatbot_id", "admin")
    chatbot_manager = ChatbotManager.from_environ()
    chatbot = chatbot_manager.get_chatbot(group_name, chatbot_id)
    logger.info(chatbot)
    for index_type, item_dict in chatbot.index_ids.items():
        if index_type != IndexType.INTENTION:
            for index_content in item_dict["value"].values():
                if "indexId" in index_content and "description" in index_content:
                    # TODO give specific retriever config
                    ToolManager.register_common_rag_tool(
                        retriever_config=event_body["chatbot_config"]["private_knowledge_config"],
                        name=index_content["indexId"],
                        scene=SceneType.COMMON,
                        description=index_content["description"],
                        pass_state=True,
                        pass_state_name='state'
                    )


def common_entry(event_body):
    """
    Entry point for the Lambda function.
    :param event_body: The event body for lambda function.
    return: answer(str)
    """
    global app, app_agent
    if app is None:
        app = build_graph(ChatbotState)

    # if app_agent is None:
    #     app_agent = build_agent_graph(ChatbotState)

    # debuging
    if is_running_local():
        with open("common_entry_workflow.png", "wb") as f:
            f.write(app.get_graph().draw_mermaid_png())

        # with open("common_entry_agent_workflow.png", "wb") as f:
        #     f.write(app_agent.get_graph().draw_mermaid_png())

    ################################################################################
    # prepare inputs and invoke graph
    event_body["chatbot_config"] = CommonConfigParser.from_chatbot_config(
        event_body["chatbot_config"]
    )
    logger.info(event_body)
    chatbot_config = event_body["chatbot_config"]
    query = event_body["query"]
    use_history = chatbot_config["use_history"]
    chat_history = event_body["chat_history"] if use_history else []
    stream = event_body["stream"]
    message_id = event_body["custom_message_id"]
    ws_connection_id = event_body["ws_connection_id"]
    enable_trace = chatbot_config["enable_trace"]
    
    # register as rag tool for each aos index
    register_rag_tool_from_config(event_body)
    
    # define all knowledge rag tool
    all_knowledge_rag_tool = ToolManager.register_common_rag_tool(
                retriever_config=event_body["chatbot_config"]["private_knowledge_config"],
                name="all_knowledge_rag_tool",
                scene=SceneType.COMMON,
                description="all knowledge rag tool",
                pass_state=True,
                pass_state_name='state'
    )

    # invoke graph and get results
    response = app.invoke(
        {
            "event_body": event_body,
            "stream": stream,
            "chatbot_config": chatbot_config,
            "query": query,
            "enable_trace": enable_trace,
            "trace_infos": [],
            "message_id": message_id,
            "chat_history": chat_history,
            "agent_tool_history": [],
            "ws_connection_id": ws_connection_id,
            "debug_infos": {},
            "extra_response": {},
            "qq_match_results": [],
            "last_tool_calls_results":None,
            "all_knowledge_rag_tool":all_knowledge_rag_tool,
            "tools":None,
            # "agent_repeated_call_limit": chatbot_config["agent_repeated_call_limit"],
            # "agent_current_call_number": 0,
            "ddb_additional_kwargs": {},

        }
    )
    return response["app_response"]


main_chain_entry = common_entry
